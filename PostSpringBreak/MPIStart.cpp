/*
Now that time and distance are relatively the same thing,
Computers have gotten faster, however we are flatlining.
The cose goes down for these types of productions, therefore, there are faster computers.
WHY did computers flatline, is there really a theoretical cap in computing power?
How do you do high amounts of BigData computation while our computers suck.
The more electrical impulses that go through a smaller computer, shit gets hawt.
There is a physical limit to the amount of electronic signals one can pass, so heat is a serious issue.
Fans have been invented, and water cooling, and nitro cooling. All just to keep the shit cool.
Air conditioners, wind cooling, all sorts of resources to decrease heat, but it cannot ever be cool enough.
There is a physical limit, based on physics, before everything blows to all smithereens.

The more signals in the Bus, x8, x16, x32, x64, the hotter it gets. Arcs gotta be able to handle
all that heat and all the connectivity. These "Road Maps" complicate things. More twisty shit,
the harder it is to deal with. There are bridges that make things not collide anymore.
There was nothing else we could do with computer bridges, once you hit 0, you cannot simplify or decrease
the distance any further. Previously we deal with heat, but now we are currently dealing with the software.
We either do really good algorithms, or bad algorithms due to run time operations. We keep figuring out
a better algo, and a better algo. Someone said mathematically speaking, it is impossible for someone
to come up with a better way to do this. You can't have a difference of opinion, or an argument, when we
as computational masters are always right.

Later and later, you start figuring out how to make all this shit better. Think lemonade stand.
Optimize the results, but after a point, there isn't much left to optimize.
--------------------------------------------------------------------------------
|500 envelops. Stamp it, send it. 1 Unit per Envelope.							|
|Just double up computers, then #winning.										|
|After a certain point, it might just be easier if we do it outselves.			|
|We need to create a perfect set of instructions. A Gods Algo for all this shit.	|
--------------------------------------------------------------------------------
What is Parallel Program. More than 1 CPU at a time, following a specific set of instructions.

Computer --> Think a human body. Brain, lungs, liver, kidney, etc. All form a "Computer"
CPU --> Brain of computer
Process --> The Instructions
Processor --> The Instructor or CPU
Core --> 1-8 Cells for the brain. Think sections of brain

|--| Effectively means a computer.
Watch out for over head cost. Currently Minimal. Day 1.

Example. Bake a Cake
Make Some Batter
Make Some Icing
Ice the Tray
Place the Batter in a Tray
Preheat to 375
Cook batter for 25-30 Min
Cool for 5-10
Ice until completion

Main Issue #1: Bottlenecking: Portion of computation where all CPU's have to wait until that portion
is complete. 
The idea that one computation has to be completed before anyone can complete anything else.

Main Issue #2: Task Driven v Data Driven Parallel: 
Data: Everyone does the same thing on their piece of work. Cuts time, but might not be resourceful enough.
Task: You do a task, then I will do a task, then we smash together and #win

Every Process does the same thing on their piece of the pie, and combine all together.
Ignore the overhead cost. If you avoid overhead cost it is embarrassingly parallel.

Ignore the communication cost of the algorithms.
*/
